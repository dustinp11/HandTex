{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-5 Vision Baseline\n",
    "Evaluate GPT-5's vision capabilities on handwritten math to LaTeX conversion.\n",
    "\n",
    "**Setup on Kaggle:** Add your OpenAI API key as a Kaggle secret named `OPENAI_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q openai datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import base64\n",
    "import random\n",
    "from io import BytesIO\n",
    "\n",
    "from openai import OpenAI\n",
    "from datasets import load_dataset\n",
    "\n",
    "# On Kaggle, use Kaggle Secrets for the API key\n",
    "# Go to Add-ons > Secrets > add OPENAI_API_KEY\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    api_key = UserSecretsClient().get_secret(\"OPENAI_API_KEY\")\n",
    "except Exception:\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "assert api_key, \"OPENAI_API_KEY not found. Add it as a Kaggle secret or env var.\"\n",
    "client = OpenAI(api_key=api_key)\n",
    "print(\"OpenAI client ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "NUM_SAMPLES = 50\n",
    "MODEL = \"gpt-5\"\n",
    "DELAY_BETWEEN_CALLS = 0.5\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"deepcopy/MathWriting-human\", split=\"test\")\n",
    "print(f\"Test set size: {len(ds)}\")\n",
    "\n",
    "random.seed(SEED)\n",
    "indices = random.sample(range(len(ds)), NUM_SAMPLES)\n",
    "samples = [ds[i] for i in indices]\n",
    "print(f\"Sampled {NUM_SAMPLES} test images (seed={SEED})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview a few samples\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for ax, s in zip(axes, samples[:5]):\n",
    "    ax.imshow(s[\"image\"], cmap=\"gray\")\n",
    "    ax.set_title(s[\"latex\"][:30], fontsize=9)\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = (\n",
    "    \"This image contains a handwritten mathematical equation or expression. \"\n",
    "    \"Return ONLY the LaTeX markup that represents this equation. \"\n",
    "    \"Do not include dollar signs, \\\\begin{equation}, or any other wrapper. \"\n",
    "    \"Return just the raw LaTeX string, nothing else.\"\n",
    ")\n",
    "\n",
    "\n",
    "def encode_image_to_base64(pil_image):\n",
    "    buf = BytesIO()\n",
    "    pil_image.save(buf, format=\"PNG\")\n",
    "    return base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def strip_code_fences(text):\n",
    "    return re.sub(r\"^```(?:latex)?\\n?|\\n?```$\", \"\", text, flags=re.MULTILINE).strip()\n",
    "\n",
    "\n",
    "def predict_latex(pil_image):\n",
    "    b64 = encode_image_to_base64(pil_image)\n",
    "    response = client.responses.create(\n",
    "        model=MODEL,\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"input_text\", \"text\": PROMPT},\n",
    "                    {\n",
    "                        \"type\": \"input_image\",\n",
    "                        \"image_url\": f\"data:image/png;base64,{b64}\",\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    return strip_code_fences(response.output_text.strip())\n",
    "\n",
    "\n",
    "def normalized_edit_distance(pred, target):\n",
    "    m, n = len(pred), len(target)\n",
    "    if m == 0 and n == 0:\n",
    "        return 0.0\n",
    "    dp = list(range(n + 1))\n",
    "    for i in range(1, m + 1):\n",
    "        prev = dp[0]\n",
    "        dp[0] = i\n",
    "        for j in range(1, n + 1):\n",
    "            temp = dp[j]\n",
    "            if pred[i - 1] == target[j - 1]:\n",
    "                dp[j] = prev\n",
    "            else:\n",
    "                dp[j] = 1 + min(dp[j], dp[j - 1], prev)\n",
    "            prev = temp\n",
    "    return dp[n] / max(m, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "exact_matches = 0\n",
    "total_edit_dist = 0.0\n",
    "\n",
    "for i, sample in enumerate(samples):\n",
    "    ground_truth = sample[\"latex\"]\n",
    "    image = sample[\"image\"]\n",
    "\n",
    "    try:\n",
    "        prediction = predict_latex(image)\n",
    "    except Exception as e:\n",
    "        print(f\"  [{i+1}/{NUM_SAMPLES}] ERROR: {e}\")\n",
    "        prediction = \"\"\n",
    "\n",
    "    is_exact = prediction == ground_truth\n",
    "    edit_dist = normalized_edit_distance(prediction, ground_truth)\n",
    "\n",
    "    if is_exact:\n",
    "        exact_matches += 1\n",
    "    total_edit_dist += edit_dist\n",
    "\n",
    "    results.append({\n",
    "        \"index\": indices[i],\n",
    "        \"ground_truth\": ground_truth,\n",
    "        \"prediction\": prediction,\n",
    "        \"exact_match\": is_exact,\n",
    "        \"normalized_edit_distance\": round(edit_dist, 4),\n",
    "    })\n",
    "\n",
    "    status = \"EXACT\" if is_exact else f\"edit_dist={edit_dist:.4f}\"\n",
    "    print(f\"  [{i+1}/{NUM_SAMPLES}] {status}\")\n",
    "    print(f\"    GT:   {ground_truth[:80]}\")\n",
    "    print(f\"    Pred: {prediction[:80]}\")\n",
    "\n",
    "    if i < NUM_SAMPLES - 1:\n",
    "        time.sleep(DELAY_BETWEEN_CALLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary\n",
    "accuracy = exact_matches / NUM_SAMPLES\n",
    "avg_edit_dist = total_edit_dist / NUM_SAMPLES\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Model:                    {MODEL}\")\n",
    "print(f\"Samples:                  {NUM_SAMPLES}\")\n",
    "print(f\"Exact match accuracy:     {accuracy:.2%} ({exact_matches}/{NUM_SAMPLES})\")\n",
    "print(f\"Avg normalized edit dist: {avg_edit_dist:.4f}\")\n",
    "\n",
    "# save results\n",
    "output = {\n",
    "    \"summary\": {\n",
    "        \"model\": MODEL,\n",
    "        \"num_samples\": NUM_SAMPLES,\n",
    "        \"seed\": SEED,\n",
    "        \"exact_match_accuracy\": round(accuracy, 4),\n",
    "        \"avg_normalized_edit_distance\": round(avg_edit_dist, 4),\n",
    "    },\n",
    "    \"results\": results,\n",
    "}\n",
    "\n",
    "with open(\"gpt5_baseline_results.json\", \"w\") as f:\n",
    "    json.dump(output, f, indent=2)\n",
    "\n",
    "print(f\"\\nResults saved to gpt5_baseline_results.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
